# Nexus

ä¸€ä¸ªé«˜æ€§èƒ½çš„ LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ç½‘å…³ç³»ç»Ÿï¼Œé›†æˆäº† llm-adapter å’Œ AgentFlow ä¸¤ä¸ªç‹¬ç«‹å·¥å…·ã€‚

## æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **ç»Ÿä¸€æ¥å£** - ä¸ºå¤šç§ LLM æä¾›å•†æä¾›ç»Ÿä¸€çš„è°ƒç”¨æ¥å£ï¼ˆåŸºäº llm-adapterï¼‰
- ğŸ¤– **å¤šä»£ç†åä½œ** - æ”¯æŒå¤šä»£ç†ç¼–æ’å’Œå·¥ä½œæµï¼ˆåŸºäº AgentFlowï¼‰
- ğŸš€ **æ™ºèƒ½è·¯ç”±** - å¤šç§è·¯ç”±ç­–ç•¥ï¼ˆè½®è¯¢ã€éšæœºã€åŠ æƒç­‰ï¼‰
- âš™ï¸ **é…ç½®ç®¡ç†** - è¿è¡Œæ—¶é…ç½®ç®¡ç†
- ğŸ“Š **ç›‘æ§å¯è§‚æµ‹** - æ—¥å¿—ã€æŒ‡æ ‡ã€å®¡è®¡ã€è¿½è¸ª
- ğŸ’¾ **ç¼“å­˜æ”¯æŒ** - Redis + å†…å­˜ç¼“å­˜

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å¯åŠ¨æœåŠ¡

```bash
# æ–¹æ³• 1: ç›´æ¥è¿è¡Œ
cargo run

# æ–¹æ³• 2: ä½¿ç”¨ Docker Compose
docker-compose up -d
```

æœåŠ¡å°†åœ¨ `http://localhost:3000` å¯åŠ¨ã€‚

### é…ç½® API Key

```bash
curl -X PUT http://localhost:3000/api/config/reload/adapter \
  -H "Content-Type: application/json" \
  -d '{
    "name": "openai",
    "api_key": "sk-your-key",
    "model": "gpt-3.5-turbo",
    "base_url": "https://api.openai.com/v1",
    "enabled": true
  }'
```

### è°ƒç”¨æ¨¡å‹

```bash
curl -X POST http://localhost:3000/api/invoke \
  -H "Content-Type: application/json" \
  -d '{
    "input": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
    "adapter": "openai"
  }'
```

## ğŸ“– æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](./docs/QUICKSTART.md)
- [æ¶æ„è®¾è®¡](./docs/ARCHITECTURE.md)
- [API æ–‡æ¡£](./docs/FRONTEND_API_GUIDE.md)
- [éƒ¨ç½²æŒ‡å—](./docs/DEPLOYMENT.md)
- [æµ‹è¯•æ–‡æ¡£](./tests/README.md)

## ğŸ—ï¸ æ¶æ„

Nexus é€šè¿‡é›†æˆå±‚ä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹å·¥å…·ï¼š

```
Nexus
 â”œâ”€â†’ llm-adapterï¼ˆLLM è°ƒç”¨ï¼‰
 â””â”€â†’ AgentFlowï¼ˆå¤šä»£ç†åä½œï¼‰

é›†æˆå±‚: src/integration/llm_agent.rs
```

## ğŸ”§ æŠ€æœ¯æ ˆ

- **Web æ¡†æ¶**: Axum
- **LLM é€‚é…å™¨**: llm-adapter
- **å¤šä»£ç†æ¡†æ¶**: AgentFlow
- **å¼‚æ­¥è¿è¡Œæ—¶**: Tokio
- **ç¼“å­˜**: Redis
- **ç›‘æ§**: Prometheus, Tracing

## ğŸ“ API æ–‡æ¡£

è®¿é—® Swagger UIï¼š`http://localhost:3000/docs`

## License

MIT

